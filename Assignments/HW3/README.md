## Implementing a Multi-Layer Perceptron (MLP) from Scratch. (Q3_numpy.ipynb)
writing some neural network components with names similar to those of Keras and Pytorch libraries like Dense, Sigmoid, Sequential, Relu, ...  
each of these components has functions like forward_pass, backward_pass, and optimize.  
I used the model to learn the y=x^2 function and it went the correct way to learn it.  
it is written in a way that can be leveraged to define other popular components in neural networks.  
