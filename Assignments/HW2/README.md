## Implementing a Multi-Layer Perceptron (MLP) from scratch. (Q5.ipynb)
writing some neural network components with names similar to those of Keras and Pytorch libraries like Dense, Sigmoid, Sequential, ...
each of these components has functions like forward_pass, backward_pass, and optimize.
I used the model to learn the XNOR function and it went the correct way to learn it.
it is written in a way that can be leveraged to define other popular components in neural networks.
